{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AK-Github-0/LangChain/blob/main/Building_a_Conversational_RAG_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f35e984-9a91-46da-b827-6827802206d2",
      "metadata": {
        "id": "3f35e984-9a91-46da-b827-6827802206d2"
      },
      "source": [
        " # Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5be5248d-2c0e-41aa-a12b-c65f1328f9d6",
      "metadata": {
        "id": "5be5248d-2c0e-41aa-a12b-c65f1328f9d6"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-chroma bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V6ZG3OP3amZ",
        "outputId": "3893255a-b3f9-4a13-a9cd-c5e29b8daaad"
      },
      "id": "2V6ZG3OP3amZ",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.0.64-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph) (0.1.75)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph) (2.7.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph) (8.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (3.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (2024.6.2)\n",
            "Installing collected packages: langgraph\n",
            "Successfully installed langgraph-0.0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doh7NMg7eT0j",
        "outputId": "fd60633b-0b89-40e7-d777-4e492940abfa"
      },
      "id": "doh7NMg7eT0j",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.41.2 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Environment"
      ],
      "metadata": {
        "id": "cGCrcJ-chE4P"
      },
      "id": "cGCrcJ-chE4P"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4cb7c463-1e08-4039-965f-0ed8ee9b2b36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cb7c463-1e08-4039-965f-0ed8ee9b2b36",
        "outputId": "1e4dedcf-d2b9-4cb8-d587-5caf2e670213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "model = ChatCohere(model=\"command-r\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "36c8696e-b85f-4f4c-817c-779312713f8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36c8696e-b85f-4f4c-817c-779312713f8c",
        "outputId": "b5c8256c-c9e9-45e0-c98b-03e7dad3e231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "if not os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dff3eef6-be59-4514-9b33-6a1bd986e349",
      "metadata": {
        "id": "dff3eef6-be59-4514-9b33-6a1bd986e349"
      },
      "outputs": [],
      "source": [
        "llm = ChatCohere(model=\"command-r\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains"
      ],
      "metadata": {
        "id": "9aTdld8uhhIW"
      },
      "id": "9aTdld8uhhIW"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c5273b83-a51d-400a-966d-f4571de4b642",
      "metadata": {
        "id": "c5273b83-a51d-400a-966d-f4571de4b642"
      },
      "outputs": [],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_cohere import CohereEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=CohereEmbeddings())\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "\n",
        "# 2. Incorporate the retriever into a question-answering chain.\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4b8485d8-6683-42e9-9e73-8d4bb40ded62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4b8485d8-6683-42e9-9e73-8d4bb40ded62",
        "outputId": "6f2a6d5d-e13e-4c86-942c-21bd8e93083d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Task decomposition is a process that breaks down a complex task into simpler, more manageable steps. It's a method to help autonomous agents plan and organize their execution of complicated missions. It can be performed in multiple ways, including by the LLM itself or with human assistance.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "response = rag_chain.invoke({\"input\": \"What is Task Decomposition?\"})\n",
        "response[\"answer\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding chat history"
      ],
      "metadata": {
        "id": "El1pWmNJm35z"
      },
      "id": "El1pWmNJm35z"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "contextualize_q_system_prompt = (\n",
        "    \"Given a chat history and the latest user question \"\n",
        "    \"which might reference context in the chat history, \"\n",
        "    \"formulate a standalone question which can be understood \"\n",
        "    \"without the chat history. Do NOT answer the question, \"\n",
        "    \"just reformulate it if needed and otherwise return it as is.\"\n",
        ")\n",
        "\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_q_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "cKr1Gptxgy20"
      },
      "id": "cKr1Gptxgy20",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "G9T3Cdkvg2vX"
      },
      "id": "G9T3Cdkvg2vX",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "question = \"What is Task Decomposition?\"\n",
        "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "chat_history.extend(\n",
        "    [\n",
        "        HumanMessage(content=question),\n",
        "        AIMessage(content=ai_msg_1[\"answer\"]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "second_question = \"What are common ways of doing it?\"\n",
        "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
        "\n",
        "print(ai_msg_2[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa1RFJsug4UM",
        "outputId": "d1acadc8-8794-4636-a5e8-b20d8d2a742d"
      },
      "id": "Oa1RFJsug4UM",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are three primary methods: \n",
            "\n",
            "- The LLM can be gently prompted with questions like \"What are the steps for...?\" or \"1. First, do this. 2. Next, do what?\". \n",
            "\n",
            "- Alternatively, the agent can follow task-specific instructions tailored to the mission. For instance, writing a story might involve outlining the plot.\n",
            "\n",
            "- The third option is human-led task decomposition, where a person directly inputs the broken-down steps into the agent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ],
      "metadata": {
        "id": "VvN7ck2Lp7IH"
      },
      "id": "VvN7ck2Lp7IH",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"What is Task Decomposition?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"abc123\"}\n",
        "    },  # constructs a key \"abc123\" in `store`.\n",
        "    )[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "gwkSVKSJqjbX",
        "outputId": "673d6a61-430d-4960-a642-41fd11df592e"
      },
      "id": "gwkSVKSJqjbX",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run babd5d04-1274-459f-96ca-6973129ef655 not found for run d74d5a1b-8895-4ab5-8c59-4eda324900e9. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Task decomposition is a process that breaks down a complex task into simpler, more manageable steps. It's a technique used by autonomous agents to plan and execute tasks more effectively by handling one step at a time. This approach makes it easier for agents to accomplish complicated missions and shed light on their thought processes.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"What are common ways of doing it?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
        ")[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "TSmn3nIvq1z4",
        "outputId": "9c07ef33-2ac3-4498-df2a-39d337998799"
      },
      "id": "TSmn3nIvq1z4",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 7f0ec1b7-18d3-4e66-8731-c4d5039136b3 not found for run 8d02d706-2f17-4918-88e6-8c0e653fd6a4. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are three primary methods: \\n\\n1. The LLM can be prompted with simple instructions to break a task down into steps, for instance, asking for \"steps for completing XYZ task\". \\n\\n2. Using more specific instructions tailored to the task, such as outlining a story. \\n\\n3. Human-directed task decomposition, where a human operator provides the steps, perhaps for a highly specialized or nuanced task requiring expert knowledge.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message in store[\"abc123\"].messages:\n",
        "    if isinstance(message, AIMessage):\n",
        "        prefix = \"AI\"\n",
        "    else:\n",
        "        prefix = \"User\"\n",
        "\n",
        "    print(f\"{prefix}: {message.content}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hH551FWq7y8",
        "outputId": "a6fc0cf4-5c70-4ec9-99eb-92ac113e196f"
      },
      "id": "2hH551FWq7y8",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What is Task Decomposition?\n",
            "\n",
            "AI: Task decomposition is a process that breaks down a complex task into simpler, more manageable steps. It's a technique used by autonomous agents to plan and execute tasks more effectively by handling one step at a time. This approach makes it easier for agents to accomplish complicated missions and shed light on their thought processes.\n",
            "\n",
            "User: What are common ways of doing it?\n",
            "\n",
            "AI: There are three primary methods: \n",
            "\n",
            "1. The LLM can be prompted with simple instructions to break a task down into steps, for instance, asking for \"steps for completing XYZ task\". \n",
            "\n",
            "2. Using more specific instructions tailored to the task, such as outlining a story. \n",
            "\n",
            "3. Human-directed task decomposition, where a human operator provides the steps, perhaps for a highly specialized or nuanced task requiring expert knowledge.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For convenience, we tie together all of the necessary steps in a single code cell:\n",
        "\n"
      ],
      "metadata": {
        "id": "iZ-MSNCkrXr1"
      },
      "id": "iZ-MSNCkrXr1"
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_cohere import CohereEmbeddings, ChatCohere\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "llm = ChatCohere(model=\"command-r\", temperature=0)\n",
        "\n",
        "\n",
        "### Construct retriever ###\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=CohereEmbeddings())\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "\n",
        "### Contextualize question ###\n",
        "contextualize_q_system_prompt = (\n",
        "    \"Given a chat history and the latest user question \"\n",
        "    \"which might reference context in the chat history, \"\n",
        "    \"formulate a standalone question which can be understood \"\n",
        "    \"without the chat history. Do NOT answer the question, \"\n",
        "    \"just reformulate it if needed and otherwise return it as is.\"\n",
        ")\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_q_prompt\n",
        ")\n",
        "\n",
        "\n",
        "### Answer question ###\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
        "\n",
        "\n",
        "### Statefully manage chat history ###\n",
        "store = {}\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")\n",
        "\n",
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"What is Task Decomposition?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"abc123\"}\n",
        "    },  # constructs a key \"abc123\" in `store`.\n",
        ")[\"answer\"]\n",
        "\n",
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"What are common ways of doing it?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
        ")[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "a4IsfcbwrUUf",
        "outputId": "d1b05f14-e986-4ac5-a7b3-aba263dfcaff"
      },
      "id": "a4IsfcbwrUUf",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run a10e7ea2-6fe0-443a-bb85-e27000792aa9 not found for run 6b90ac26-951a-42c8-b50a-9e8ae7a7f8a4. Treating as a root run.\n",
            "WARNING:langchain_core.tracers.core:Parent run 615b1e0c-072e-400c-aabc-943cf8d974ef not found for run da996ea5-97a8-427b-b29c-52ef89475708. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Some standard methods for task decomposition include:\\n\\n1. Breaking tasks down into their constituent parts or subtasks, especially when the main task has multiple steps.\\n\\n2. Creating a hierarchical structure or workflow that organizes the main task into a clear sequence of steps, sometimes with parallel processes.\\n\\n3. Identifying the main task's key parameters or variables and treating them as individual tasks to be analyzed and manipulated.\\n\\nThe goal is to simplify the original task and provide a structured approach to executing it, making it more accessible for agents or systems to understand and complete.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "0ddVIG9fsXXh"
      },
      "id": "0ddVIG9fsXXh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval tool"
      ],
      "metadata": {
        "id": "8RvC5xAN3R-m"
      },
      "id": "8RvC5xAN3R-m"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"blog_post_retriever\",\n",
        "    \"Searches and returns excerpts from the Autonomous Agents blog post.\",\n",
        ")\n",
        "tools = [tool]"
      ],
      "metadata": {
        "id": "OlHq81iMsZ6q"
      },
      "id": "OlHq81iMsZ6q",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool.invoke(\"task decomposition\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "xD8Qk6q73DVj",
        "outputId": "eff42399-cf75-428a-bc3c-2f0e4c647b81"
      },
      "id": "xD8Qk6q73DVj",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in LangChainTracer.on_tool_end callback: TracerException(\"Found chain run at ID 27444725-a97f-45f8-b06f-791da970ea6e, but expected {'tool'} run.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent constructor\n"
      ],
      "metadata": {
        "id": "vuenFE9q3MPa"
      },
      "id": "vuenFE9q3MPa"
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, tools)"
      ],
      "metadata": {
        "id": "AojCY8Ys3F-5"
      },
      "id": "AojCY8Ys3F-5",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Task Decomposition?\"\n",
        "\n",
        "for s in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=query)]},\n",
        "):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjkehWFt3hzm",
        "outputId": "bc70f145-79a5-4a3c-d6aa-c106bfa408d8"
      },
      "id": "rjkehWFt3hzm",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in LangChainTracer.on_tool_end callback: TracerException(\"Found chain run at ID c066c709-e930-4aa1-991c-26965721a548, but expected {'tool'} run.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7bb7e91b-9306-4687-8e8a-f1cbfd32c200', 'tool_calls': [{'id': '006c036d0215447da0206029a7855895', 'function': {'name': 'blog_post_retriever', 'arguments': '{\"query\": \"task decomposition\"}'}, 'type': 'function'}], 'token_count': {'output_tokens': 12}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7bb7e91b-9306-4687-8e8a-f1cbfd32c200', 'tool_calls': [{'id': '006c036d0215447da0206029a7855895', 'function': {'name': 'blog_post_retriever', 'arguments': '{\"query\": \"task decomposition\"}'}, 'type': 'function'}], 'token_count': {'output_tokens': 12}}, id='run-ec6c97d8-b814-41e5-a729-9bf9a50bd322-0', tool_calls=[{'name': 'blog_post_retriever', 'args': {'query': 'task decomposition'}, 'id': 'a2c412b4e9704bd3b11acdfa83ed869e'}])]}}\n",
            "----\n",
            "{'tools': {'messages': [ToolMessage(content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', name='blog_post_retriever', tool_call_id='a2c412b4e9704bd3b11acdfa83ed869e')]}}\n",
            "----\n",
            "{'agent': {'messages': [AIMessage(content='Task decomposition is a method of enhancing model performance on complex tasks. A model uses task decomposition to break down hard tasks into simpler, smaller steps which are more manageable for the model to complete. This technique is referred to as Chain of Thought (CoT).', additional_kwargs={'documents': [{'id': 'blog_post_retriever:0:0', 'output': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'tool_name': 'blog_post_retriever'}], 'citations': [ChatCitation(start=24, end=79, text='method of enhancing model performance on complex tasks.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=115, end=164, text='break down hard tasks into simpler, smaller steps', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=180, end=190, text='manageable', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=251, end=267, text='Chain of Thought', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=268, end=273, text='(CoT)', document_ids=['blog_post_retriever:0:0'])], 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2b16a14f-2e6e-46e2-9d50-be7497a5a806', 'token_count': {'input_tokens': 1805, 'output_tokens': 51}}, response_metadata={'documents': [{'id': 'blog_post_retriever:0:0', 'output': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'tool_name': 'blog_post_retriever'}], 'citations': [ChatCitation(start=24, end=79, text='method of enhancing model performance on complex tasks.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=115, end=164, text='break down hard tasks into simpler, smaller steps', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=180, end=190, text='manageable', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=251, end=267, text='Chain of Thought', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=268, end=273, text='(CoT)', document_ids=['blog_post_retriever:0:0'])], 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2b16a14f-2e6e-46e2-9d50-be7497a5a806', 'token_count': {'input_tokens': 1805, 'output_tokens': 51}}, id='run-25db26e8-28f9-4ccf-87c0-302eeaff31fb-0')]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
        "\n",
        "agent_executor = create_react_agent(llm, tools, checkpointer=memory)"
      ],
      "metadata": {
        "id": "kEHAiaMN4WLi"
      },
      "id": "kEHAiaMN4WLi",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
        "\n",
        "for s in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Hi! I'm bob\")]}, config=config\n",
        "):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vO3LNE64gzf",
        "outputId": "41a613da-e781-49b4-e3c3-131769510262"
      },
      "id": "2vO3LNE64gzf",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"Hi Bob! It's nice to meet you. How's it going today?\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8d11a200-06ae-45d8-8e90-b536ed836539', 'token_count': {'input_tokens': 71, 'output_tokens': 16}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8d11a200-06ae-45d8-8e90-b536ed836539', 'token_count': {'input_tokens': 71, 'output_tokens': 16}}, id='run-7623dd66-0e78-4a56-94b3-70efd62378bd-0')]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Task Decomposition?\"\n",
        "\n",
        "for s in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=query)]}, config=config\n",
        "):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "virESiqW4jJV",
        "outputId": "52127b68-4f35-4627-b594-2948b2b2d55a"
      },
      "id": "virESiqW4jJV",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in LangChainTracer.on_tool_end callback: TracerException(\"Found chain run at ID e7aa19dd-c01f-441b-9ece-55d8fc15ddc2, but expected {'tool'} run.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '228636f6-da01-4256-93a8-f7bcab8bbca8', 'tool_calls': [{'id': '2af20a12422d48d2ab4507b700a302ac', 'function': {'name': 'blog_post_retriever', 'arguments': '{\"query\": \"task decomposition\"}'}, 'type': 'function'}], 'token_count': {'output_tokens': 12}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '228636f6-da01-4256-93a8-f7bcab8bbca8', 'tool_calls': [{'id': '2af20a12422d48d2ab4507b700a302ac', 'function': {'name': 'blog_post_retriever', 'arguments': '{\"query\": \"task decomposition\"}'}, 'type': 'function'}], 'token_count': {'output_tokens': 12}}, id='run-086b55ff-33c5-4c99-919f-b9da32c35958-0', tool_calls=[{'name': 'blog_post_retriever', 'args': {'query': 'task decomposition'}, 'id': 'ce4d1e4a67014fb09d1ff80b2857e78c'}])]}}\n",
            "----\n",
            "{'tools': {'messages': [ToolMessage(content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', name='blog_post_retriever', tool_call_id='ce4d1e4a67014fb09d1ff80b2857e78c')]}}\n",
            "----\n",
            "{'agent': {'messages': [AIMessage(content='Task decomposition is a process that involves breaking down complicated tasks into simpler and smaller steps. This is a standard prompting technique used for enhancing the performance of models on complex tasks. The model is instructed to \"think step by step\" which helps decompose difficult tasks and transform them into multiple manageable tasks. This technique is referred to as Chain of Thought (CoT) and was proposed by Wei et al. in 2022.', additional_kwargs={'documents': [{'id': 'blog_post_retriever:0:0', 'output': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'tool_name': 'blog_post_retriever'}], 'citations': [ChatCitation(start=46, end=109, text='breaking down complicated tasks into simpler and smaller steps.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=120, end=148, text='standard prompting technique', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=158, end=211, text='enhancing the performance of models on complex tasks.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=225, end=235, text='instructed', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=239, end=259, text='\"think step by step\"', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=272, end=297, text='decompose difficult tasks', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=302, end=348, text='transform them into multiple manageable tasks.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=382, end=404, text='Chain of Thought (CoT)', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=425, end=444, text='Wei et al. in 2022.', document_ids=['blog_post_retriever:0:0'])], 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd17bc530-ee1f-4f99-9264-070baa8f9f7c', 'token_count': {'input_tokens': 1832, 'output_tokens': 86}}, response_metadata={'documents': [{'id': 'blog_post_retriever:0:0', 'output': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'tool_name': 'blog_post_retriever'}], 'citations': [ChatCitation(start=46, end=109, text='breaking down complicated tasks into simpler and smaller steps.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=120, end=148, text='standard prompting technique', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=158, end=211, text='enhancing the performance of models on complex tasks.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=225, end=235, text='instructed', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=239, end=259, text='\"think step by step\"', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=272, end=297, text='decompose difficult tasks', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=302, end=348, text='transform them into multiple manageable tasks.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=382, end=404, text='Chain of Thought (CoT)', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=425, end=444, text='Wei et al. in 2022.', document_ids=['blog_post_retriever:0:0'])], 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd17bc530-ee1f-4f99-9264-070baa8f9f7c', 'token_count': {'input_tokens': 1832, 'output_tokens': 86}}, id='run-f649633d-ea63-4b99-88a1-bb0d4410c9a5-0')]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What according to the blog post are common ways of doing it? redo the search\"\n",
        "\n",
        "for s in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=query)]}, config=config\n",
        "):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnQKWItc4k6L",
        "outputId": "78679797-2d91-4668-c137-057af4e44483"
      },
      "id": "nnQKWItc4k6L",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"According to the blog post, the Chain of Thought (CoT) is a standard way of doing task decomposition. The model is prompted to think step by step, which enables the decomposition of difficult tasks into multiple simpler tasks. This technique utilises more test-time computation and provides insight into the model's thought process.\", additional_kwargs={'documents': [{'id': 'blog_post_retriever:0:0', 'output': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'tool_name': 'blog_post_retriever'}], 'citations': [ChatCitation(start=32, end=54, text='Chain of Thought (CoT)', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=115, end=145, text='prompted to think step by step', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=165, end=226, text='decomposition of difficult tasks into multiple simpler tasks.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=242, end=277, text='utilises more test-time computation', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=282, end=332, text=\"provides insight into the model's thought process.\", document_ids=['blog_post_retriever:0:0'])], 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd5540a6b-0603-4134-a655-16ca789373c8', 'token_count': {'input_tokens': 1407, 'output_tokens': 64}}, response_metadata={'documents': [{'id': 'blog_post_retriever:0:0', 'output': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'tool_name': 'blog_post_retriever'}], 'citations': [ChatCitation(start=32, end=54, text='Chain of Thought (CoT)', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=115, end=145, text='prompted to think step by step', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=165, end=226, text='decomposition of difficult tasks into multiple simpler tasks.', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=242, end=277, text='utilises more test-time computation', document_ids=['blog_post_retriever:0:0']), ChatCitation(start=282, end=332, text=\"provides insight into the model's thought process.\", document_ids=['blog_post_retriever:0:0'])], 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd5540a6b-0603-4134-a655-16ca789373c8', 'token_count': {'input_tokens': 1407, 'output_tokens': 64}}, id='run-87321092-295c-44c1-b5ab-df025a6424a0-0')]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## we tie together all of the necessary steps in a single code cell"
      ],
      "metadata": {
        "id": "mBN4TPLO5Ta6"
      },
      "id": "mBN4TPLO5Ta6"
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_cohere import ChatCohere, CohereEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
        "llm = ChatCohere(model=\"command-r\", temperature=0)\n",
        "\n",
        "\n",
        "### Construct retriever ###\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=CohereEmbeddings())\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "\n",
        "### Build retriever tool ###\n",
        "tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"blog_post_retriever\",\n",
        "    \"Searches and returns excerpts from the Autonomous Agents blog post.\",\n",
        ")\n",
        "tools = [tool]\n",
        "\n",
        "\n",
        "agent_executor = create_react_agent(llm, tools, checkpointer=memory)"
      ],
      "metadata": {
        "id": "DKCLhjpo4nZo"
      },
      "id": "DKCLhjpo4nZo",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7syLIekg4rX6"
      },
      "id": "7syLIekg4rX6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}